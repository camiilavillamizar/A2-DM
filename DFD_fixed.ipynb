{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "539d6553-653d-4360-a4aa-7d9d75a2a5e6",
   "metadata": {},
   "source": [
    "# Testing Database Design Quality\n",
    "## Assignment 2: Relational Model for Uber’s Ride-Sharing System \n",
    "### Aryan Dutt, Prince Raj, Maria Camila Villamizar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99dbbd4-7809-4f78-ac51-9657d4b61720",
   "metadata": {},
   "source": [
    "Function to analyze normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c87c94e-5556-4ae1-ae36-e5948bb46af6",
   "metadata": {},
   "source": [
    "Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1c3ed171-4129-4c9b-9c15-96fb0df37a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "address_id → city_id\n",
      "address_id → postal_code\n",
      "address_id → description\n",
      "address_id → latitude\n",
      "address_id → longitude\n",
      "address_id → street_num\n",
      "address_id → street_name\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Loads data from a CSV file.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df.dropna(how=\"all\")\n",
    "\n",
    "def extract_df():\n",
    "    \"\"\"Extracts the DataFrame from the address.csv table.\"\"\"\n",
    "    file_path = \"database/new/address.csv\"\n",
    "    return load_data(file_path)\n",
    "\n",
    "def find_fds(df):\n",
    "    \"\"\"Finds functional dependencies by iterating over columns and assigning each one as RHS.\"\"\"\n",
    "    fds = []\n",
    "    columns = df.columns.tolist()\n",
    "    partition_cache = {}  # Cache for partition refinement\n",
    "\n",
    "    for rhs in columns:\n",
    "        if rhs == \"address_id\":  # address_id should not be RHS\n",
    "            continue\n",
    "\n",
    "        lhs_candidates = [col for col in columns if col != rhs]\n",
    "        minimal_lhs = explore_lhs(df, lhs_candidates, rhs, partition_cache)\n",
    "        \n",
    "        for lhs in minimal_lhs:\n",
    "            fds.append((lhs, rhs))\n",
    "\n",
    "    # Apply post-processing to remove unnecessary FDs if address_id is primary key\n",
    "    fds = filter_unnecessary_fds(fds, df)\n",
    "    return fds\n",
    "\n",
    "def explore_lhs(df, lhs_candidates, rhs, partition_cache):\n",
    "    \"\"\"Explores combinations of the left-hand side (LHS) using partition refinement.\"\"\"\n",
    "    minimal_lhs = []\n",
    "    \n",
    "    for r in range(1, len(lhs_candidates) + 1):\n",
    "        for lhs in combinations(lhs_candidates, r):\n",
    "            lhs_list = list(lhs)\n",
    "            if check_fd(df, lhs_list, rhs, partition_cache):\n",
    "                if not any(set(lhs_list).issuperset(set(existing)) for existing in minimal_lhs):\n",
    "                    minimal_lhs.append(lhs_list)\n",
    "    \n",
    "    return minimal_lhs\n",
    "\n",
    "def check_fd(df, lhs, rhs, partition_cache):\n",
    "    \"\"\"Checks if a functional dependency exists between LHS and RHS using partition intersection.\"\"\"\n",
    "    lhs_key = tuple(lhs)\n",
    "    \n",
    "    if lhs_key in partition_cache:\n",
    "        lhs_partition = partition_cache[lhs_key]\n",
    "    else:\n",
    "        lhs_partition = compute_partition(df, lhs)\n",
    "        partition_cache[lhs_key] = lhs_partition\n",
    "\n",
    "    # Compute intersection of partitions (key concept in DFD)\n",
    "    lhs_rhs_partition = compute_partition(df, lhs + [rhs])\n",
    "    \n",
    "    return len(lhs_partition) == len(lhs_rhs_partition)  # Valid FD if partitions have the same size\n",
    "\n",
    "def filter_unnecessary_fds(fds, df):\n",
    "    \"\"\"Removes unnecessary FDs if address_id determines all columns.\"\"\"\n",
    "    primary_key = \"address_id\"\n",
    "    \n",
    "    # Check if address_id is a primary key (which we already confirmed)\n",
    "    if df[primary_key].nunique() == len(df):\n",
    "        return [([\"address_id\"], rhs) for rhs in df.columns if rhs != \"address_id\"]\n",
    "    \n",
    "    return fds  # If address_id is not a primary key, return original results\n",
    "\n",
    "def compute_partition(df, attributes):\n",
    "    \"\"\"Computes the partition of a set of attributes.\"\"\"\n",
    "    partition = {}\n",
    "    for index, row in df.iterrows():\n",
    "        key = tuple(row[attr] for attr in attributes)\n",
    "        if key not in partition:\n",
    "            partition[key] = set()\n",
    "        partition[key].add(index)\n",
    "    return partition\n",
    "\n",
    "def prune_candidates(lhs_sets):\n",
    "    \"\"\"Efficient pruning using a dictionary of subsets.\"\"\"\n",
    "    pruned = {}\n",
    "    for lhs in lhs_sets:\n",
    "        key = frozenset(lhs)\n",
    "        if not any(existing.issubset(key) for existing in pruned):\n",
    "            pruned[key] = lhs\n",
    "    return list(pruned.values())\n",
    "\n",
    "def manage_memory(partition_cache, max_size=1000):\n",
    "    \"\"\"Removes old partitions to free memory if the cache exceeds a certain size.\"\"\"\n",
    "    if len(partition_cache) > max_size:\n",
    "        keys_to_remove = list(partition_cache.keys())[:len(partition_cache) - max_size]\n",
    "        for key in keys_to_remove:\n",
    "            del partition_cache[key]\n",
    "\n",
    "# Run the algorithm\n",
    "df = extract_df()\n",
    "fds = find_fds(df)\n",
    "\n",
    "# Display results\n",
    "for lhs, rhs in fds:\n",
    "    print(f\"{', '.join(lhs)} → {rhs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b67ff-a8db-4f77-9656-f26fbdd07f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
